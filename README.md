# Awesome-Transformer-PDE

## Transformer for Partial Differential Equations (PDEs)

Recently, there are a growing number of papers trying to solve PDEs with Transformer. This respository is trying to collect and sort papers and other format materials in this field.

## ðŸ“‘Papers

| Date  |                                                     Institute                                                      | Publication |                                                                   Paper                                                                   |                                      Keywords                                       |
| :---: | :----------------------------------------------------------------------------------------------------------------: | :---------: | :---------------------------------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------------------------: |
| 21.11 |                    Department of Mathematics and Statistics Washington University in St. Louis                     |    arxiv    |                               [Choose a Transformer: Fourier or Galerkin](http://arxiv.org/abs/2105.14995)                                |       **Fourier Transforms**&**Galerkin Methods**&**Transformer Techniques**        |
| 22.02 |            Scientific Computing and Artificial Intelligence (SCAI) Laboratory, University of Notre Dame            |    arxiv    |                               [Transformers for Modeling Physical Systems](http://arxiv.org/abs/2010.03957)                               |   **Physical Systems Modeling**&**Transformer Applications**&**Systems Dynamics**   |
| 22.03 |                         NVIDIA & California Institute of Technology & Stanford University                          |    arxiv    |               [Adaptive Fourier Neural Operators: Efficient Token Mixers for Transformers](http://arxiv.org/abs/2111.13587)               |         **Fourier Neural Operators**&**Token Mixing**&**Adaptive Learning**         |
| 22.05 |                                    Tufts University & University of Notre Dame                                     |    arXiv    |                    [Predicting Physics in Mesh-reduced Space with Temporal Attention](http://arxiv.org/abs/2201.09113)                    |          **Mesh Reduction**&**Temporal Attention**&**Physics Prediction**           |
| 22.11 |                 Microsoft Autonomous Systems and Robotics Research & Microsoft Research AI4Science                 |    arxiv    |                      [Towards Multi-spatiotemporal-scale Generalized PDE Modeling](http://arxiv.org/abs/2209.15616)                       |     **Multi-spatiotemporal Modeling**&**Generalized PDEs**&**Scale Adaptation**     |
| 23.03 |                                 Department of Mathematics University of California                                 |    arxiv    |                           [Transformer Meets Boundary Value Inverse Problems](http://arxiv.org/abs/2209.14977)                            | **Boundary Value Problems**&**Inverse Problem Solving**&**Transformer Adaptations** |
| 23.03 |                               Department of Applied Mathematics Tel Aviv University                                |    arxiv    |                                   [ViTO: Vision Transformer-Operator](http://arxiv.org/abs/2303.08891)                                    |          **Vision Transformers**&**Operator Theory**&**Visual Computing**           |
| 23.04 |                          Department of Mechanical Engineering Carnegie Mellon University                           |    arxiv    |                   [Transformer for Partial Differential Equations' Operator Learning](http://arxiv.org/abs/2205.13671)                    |      **Operator Learning**&**Transformers in Mathematics**&**PDE Techniques**       |
| 23.05 |                            Carnegie Mellon University Mechanical Engineering Department                            |    arxiv    |                            [Scalable Transformer for PDE Surrogate Modeling](https://arxiv.org/abs/2305.17560)                            |                   **Scalable Algorithms**&**Surrogate Modeling**                    |
| 23.06 | Dept. of Comp. Sci. & Techn., Institute for AI, BNRist Center, Tsinghua-Bosch Joint ML Center, Tsinghua University |    arxiv    |                   [GNOT: A General Neural Operator Transformer for Operator Learning](http://arxiv.org/abs/2302.14376)                    |    **General Neural Operators**&**Operator Learning**&**Transformation Methods**    |
| 23.06 |                                         Ecole Polytechnique, Paris, France                                         |    arxiv    |                        [Neural Multigrid Memory For Computational Fluid Dynamics](http://arxiv.org/abs/2306.12545)                        |  **Multigrid Techniques**&**Computational Fluid Dynamics**&**Memory Enhancement**   |
| 23.06 |                          Department of Mechanical Engineering, Carnegie Mellon University                          |    arxiv    |                                   [Physics Informed Token Transformer](http://arxiv.org/abs/2305.08757)                                   | **Physics-Informed Learning**&**Token-based Models**&**Transformative Approaches**  |
| 23.07 |     School of Mathematical Sciences, Institute of Natural Sciences and MOE-LSC, Shanghai Jiao Tong University      |    arxiv    |       [Mitigating spectral bias for the multiscale operator learning with hierarchical attention](http://arxiv.org/abs/2210.10890)        |  **Spectral Bias Mitigation**&**Multiscale Operators**&**Hierarchical Attention**   |
| 23.10 |                                                 Flatiron Institute                                                 |    arxiv    |                       [Multiple Physics Pretraining for Physical Surrogate Models](http://arxiv.org/abs/2310.02994)                       |    **Physics Pretraining**&**Surrogate Models**&**Multidisciplinary Approaches**    |
| 23.11 |                          Department of Mechanical Engineering, Carnegie Mellon University                          |    arxiv    |             [Multi-scale Time-stepping of Partial Differential Equations with Transformers](http://arxiv.org/abs/2311.02225)              |     **Multi-scale Modeling**&**Time-stepping Methods**&**Transformers in PDEs**     |
| 23.11 |                                                 Merantix Momentum                                                  |    arxiv    |                     [Multiscale Neural Operators for Solving Time-Independent PDEs](http://arxiv.org/abs/2311.05964)                      |  **Multiscale Neural Operators**&**Time-Independent PDEs**&**Solution Techniques**  |
| 24.01 |                                                 NVIDIA &  Caltech                                                  |    arxiv    |                  [Neural Operators for Accelerating Scientific Simulations and Design](http://arxiv.org/abs/2309.15325)                   |      **Neural Operators**&**Scientific Simulations**&**Accelerated Computing**      |
| 24.02 |                                        Department of Mathematics, MIT, USA                                         |    arXiv    |              [HAMLET: Graph Transformer Neural Operator for Partial Differential Equations](http://arxiv.org/abs/2402.03541)              |           **Graph-Based Modeling**&**Neural Operators**&**PDEs Analysis**           |
| 24.02 |                         ELLIS Unit Linz, Institute for Machine Learning, JKU Linz, Austria                         |    arXiv    |                                     [Universal Physics Transformers](http://arxiv.org/abs/2402.12365)                                     |     **Universal Modeling**&**Physics Applications**&**Transformer Technology**      |
| 24.02 |                     Beijing International Center for Mathematical Research, Peking University                      |    arxiv    |        [PDEformer: Towards a Foundation Model for One-Dimensional Partial Differential Equations](http://arxiv.org/abs/2402.12652)        |        **Foundation Models**&**One-Dimensional PDEs**&**Advanced Modeling**         |
| 24.02 |                                                 Beihang University                                                 |    arxiv    |              [Building Flexible Machine Learning Models for Scientific Computing at Scale](http://arxiv.org/abs/2402.16014)               |       **Flexible ML Models**&**Scientific Computing**&**Scalable Solutions**        |
| 24.03 | Dept. of Comp. Sci. & Techn., Institute for AI, BNRist Center, Tsinghua-Bosch Joint ML Center, Tsinghua University |    arxiv    |         [DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE Pre-Training](http://arxiv.org/abs/2403.03542)          |     **Auto-Regressive Learning**&**Denoising Techniques**&**PDE Pre-Training**      |
| 24.03 |                                   University of Science and Technology of China                                    |    arxiv    |    [Spatio-Temporal Fluid Dynamics Modeling via Physical-Awareness and Parameter Diffusion Guidance](http://arxiv.org/abs/2403.13850)     |       **Spatio-Temporal Modeling**&**Fluid Dynamics**&**Parameter Diffusion**       |
| 24.03 |                                   University of Science and Technology of China                                    |  AAAI 2024  | [Earthfarsser: Versatile Spatio-Temporal Dynamical Systems Modeling in One Model](https://ojs.aaai.org/index.php/AAAI/article/view/29521) |    **Spatio-Temporal Systems**&**Dynamical Modeling**&**Integrated Approaches**     |

## ðŸ“‘Papersï¼ˆTransformer & Operator learningï¼‰

| Date  |                                                                                                                                 Institute                                                                                                                                  | Publication |                                                                    Paper                                                                    |                                              Keywords                                              |
| :---: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :---------: | :-----------------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------: |
| 24.14 |                                  Department of Mathematics University of Maryland College Park College Park, MD, USA & Department of Mathematics Department of Computer Science University of Maryland College Park College Park, MD, USA                                  |    arxiv    |   [FMint: Bridging Human Designed and Data Pretrained Models for Differential Equation Foundation Model](http://arxiv.org/abs/2404.14688)   |      **Foundation Model**&**Dynamical Systems**&**Fast Simulation**&** In-context Learning**       |
| 24.04 | Department of Mathematical Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA & Department of Mathematics, University of California, Los Angeles, Los Angeles, CA 90095, USA & Department of Mathematics, Florida State University, Tallahassee, FL 32304, USA |    arxiv    | [Towards a Foundation Model for Partial Differential Equations: Multi-Operator Learning and Extrapolation](http://arxiv.org/abs/2404.12355) |         **Multi-modal**&**Multi-Operator Learning**&**Foundation Model**&**Extrapolation**         |
| 24.04 |                                    Department of Computer Science, Purdue University, IN, USA & Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena CA 91125 & NVIDIA, Santa Clara, CA 9505                                    |    arXiv    |              [Pretraining Codomain Attention Neural Operators for Solving Multiphysics PDEs](http://arxiv.org/abs/2403.12553)               |            **Self-supervised learning**&**Pretraining model**&**Multiple PDE systems**             |
| 24.02 |                                                              Department of Statistics, University of California, Berkeley & International Computer Science Institute & Lawrence Berkeley National Laboratory                                                               |    arxiv    |          [Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning](http://arxiv.org/abs/2402.15734)           |             **Operator Learning**&**Unsupervised Pretraining**&**In-Context Learning**             |
| 24.01 |                                                                                                        Department of Mathematics, UCLA, Los Angeles, CA 90095, USA                                                                                                         |    arxiv    |   [PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar Nonlinear Conservation Laws](http://arxiv.org/abs/2401.07364)   | **PDE Generalization**&**In-Context Operator Networks**& **1D Scalar Nonlinear Conservation Laws** |

## ðŸ“‘Papersï¼ˆnon-Transformerï¼‰

| Date  |                                                                                                                                   Institute                                                                                                                                    | Publication |                                                              Paper                                                               |                                        Keywords                                         |
| :---: | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :---------: | :------------------------------------------------------------------------------------------------------------------------------: | :-------------------------------------------------------------------------------------: |
| 24.04 |                                                                                                Department of Mathematics, Florida State University, Tallahassee, FL 32304, USA                                                                                                 |    arxiv    |               [MODNO: Multi Operator Learning With Distributed Neural Operators](http://arxiv.org/abs/2404.02892)                |           **multi-operator learning (MOL)**&**Distributed Neural Operators**            |
| 24.03 |                                               Department of Computer Science, Virginia Tech & Department of Computer Science, University of Pittsburgh & Department of Computer Science and Engineering, University of Minnesota                                               |    arxiv    |            [Knowledge-guided Machine Learning: Current Trends and Future Prospects](http://arxiv.org/abs/2403.15989)             | **Knowledge-guided machine learning (KGML)**&**Scientific knowledge**&**ML frameworks** |
| 24.03 |               The NSF AI Institute for Artificial Intelligence and Fundamental Interactions Center for Theoretical Physics, Massachusetts Institute of Technology, Cambridge, MA 02139, USA Department of Physics, Harvard University, Cambridge, MA 02138, USA                |    arxiv    | [PAPERCLIP: Associating Astronomical Observations and Natural Language with Multi-Modal Models](http://arxiv.org/abs/2403.08851) |   **Multi-Modal Models**&**Astronomical Observations**&**Natural Language**&**CLIP**    |
| 24.03 | Massachusetts Institute of Technology, Cambridge, United States & SLAC National Accelerator Laboratory, Stanford, United States & I-X, Imperial College, London, United Kingdom & Institute for Artificial Intelligence and Fundamental Interactions, Cambridge, United States |    arxiv    |        [Re-Simulation-based Self-Supervised Learning for Pre-Training Foundation Models](http://arxiv.org/abs/2403.07066)        |          **Self-Supervised Learning**&**Contrastive learning**&**Simulation**           |
## ðŸ“–Others

## Contact
If you like, please star or fork.

Welcome any comments or feedbacks!

Email: xxx@buaa.edu.cn
